{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_classes = 10\n",
    "epochs = 100\n",
    "data_augmentation = True\n",
    "num_predictions = 20\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_cifar10_trained_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSProp optimizer\n",
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# Train model using RMSProp\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    }
   ],
   "source": [
    "#convert maxtrix into an m * n matrix\n",
    "adj_x_train = np.zeros((3072,x_train.shape[0]))\n",
    "for g in range(x_train.shape[0]):\n",
    "    l = x_train[g]\n",
    "    for h in range(x_train.shape[3]):\n",
    "        for j in range(x_train.shape[1]):\n",
    "            for i in range(x_train.shape[2]):\n",
    "                adj_x_train[((h*1024) + (j*32) + (i)),g] = l[j, i, h]\n",
    "print('finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    }
   ],
   "source": [
    "adj_x_test = np.zeros((3072,x_test.shape[0]))\n",
    "for g in range(x_test.shape[0]):\n",
    "    l = x_test[g]\n",
    "    for h in range(x_test.shape[3]):\n",
    "        for j in range(x_test.shape[1]):\n",
    "            for i in range(x_test.shape[2]):\n",
    "                adj_x_test[((h*1024) + (j*32) + (i)),g] = l[j, i, h]\n",
    "print('finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    }
   ],
   "source": [
    "x_test_new = adj_x_test.T\n",
    "print('finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    }
   ],
   "source": [
    "x_train_new = adj_x_train.T\n",
    "print('finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished-2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca_100 = PCA(n_components = 15)\n",
    "pca_result_100 = pca_100.fit_transform(x_train_new)\n",
    "X_train_pca = pca_100.transform(x_train_new)\n",
    "X_recon_train = X_train_pca.dot(pca_100.components_) + pca_100.mean_\n",
    "print('finished-2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    }
   ],
   "source": [
    "# perform pca on our m x n matrices\n",
    "pca_100_test = PCA(n_components = 15)\n",
    "pca_result_100_test = pca_100_test.fit_transform(x_test_new)\n",
    "X_test_pca = pca_100_test.transform(x_test_new)\n",
    "X_recon_test = X_test_pca.dot(pca_100_test.components_) + pca_100_test.mean_\n",
    "print('finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def con_4d(X):\n",
    "    X_4D = np.zeros((X.shape[0],32,32,3))\n",
    "    for m in range(X.shape[0]):\n",
    "        for n in range(X.shape[1]):\n",
    "            #print(m, int(n/32), n % 32, int(n/1024))\n",
    "            X_4D[m, (int(n/32) - int(n/1024) * 32),(n % 32), int(n/1024)] = X[m,n]\n",
    "    return X_4D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    }
   ],
   "source": [
    "# convert the testing and training data back into 4D array\n",
    "x_train = con_4d(X_recon_train)\n",
    "x_test = con_4d(X_recon_test)\n",
    "print('finished')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using real-time data augmentation.\n"
     ]
    }
   ],
   "source": [
    "## Variations of data augmentation ##\n",
    "\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # Real time augmentation\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        # randomly shift images horizontally (fraction of total width)\n",
    "        width_shift_range=0.1,\n",
    "        # randomly shift images vertically (fraction of total height)\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.,  # set range for random shear\n",
    "        zoom_range=0.,  # set range for random zoom\n",
    "        channel_shift_range=0.,  # set range for random channel shifts\n",
    "        # set mode for filling points outside the input boundaries\n",
    "        fill_mode='nearest',\n",
    "        cval=0.,  # value used for fill_mode = \"constant\"\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False,  # randomly flip images\n",
    "        # set rescaling factor (applied before any other transformation)\n",
    "        rescale=None,\n",
    "        # set function that will be applied on each input\n",
    "        preprocessing_function=None,\n",
    "        # image data format, either \"channels_first\" or \"channels_last\"\n",
    "        data_format=None,\n",
    "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "        validation_split=0.0)\n",
    "\n",
    "    # Compute quantities required for feature-wise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "313/312 [==============================] - 13s 40ms/step - loss: 2.1754 - acc: 0.1762 - val_loss: 2.0587 - val_acc: 0.2345\n",
      "Epoch 2/100\n",
      "313/312 [==============================] - 9s 28ms/step - loss: 2.0474 - acc: 0.2349 - val_loss: 1.9869 - val_acc: 0.2921\n",
      "Epoch 3/100\n",
      "313/312 [==============================] - 8s 27ms/step - loss: 1.9866 - acc: 0.2751 - val_loss: 1.9532 - val_acc: 0.2932\n",
      "Epoch 4/100\n",
      "313/312 [==============================] - 8s 27ms/step - loss: 1.9526 - acc: 0.2900 - val_loss: 1.8865 - val_acc: 0.3251\n",
      "Epoch 5/100\n",
      "313/312 [==============================] - 8s 27ms/step - loss: 1.9284 - acc: 0.2981 - val_loss: 1.8548 - val_acc: 0.3334\n",
      "Epoch 6/100\n",
      "313/312 [==============================] - 8s 27ms/step - loss: 1.9027 - acc: 0.3077 - val_loss: 1.8324 - val_acc: 0.3471\n",
      "Epoch 7/100\n",
      "313/312 [==============================] - 8s 27ms/step - loss: 1.8688 - acc: 0.3139 - val_loss: 1.7938 - val_acc: 0.3574\n",
      "Epoch 8/100\n",
      "313/312 [==============================] - 9s 27ms/step - loss: 1.8502 - acc: 0.3265 - val_loss: 1.7854 - val_acc: 0.3587\n",
      "Epoch 9/100\n",
      "313/312 [==============================] - 8s 27ms/step - loss: 1.8249 - acc: 0.3388 - val_loss: 1.7708 - val_acc: 0.3583\n",
      "Epoch 10/100\n",
      "313/312 [==============================] - 8s 26ms/step - loss: 1.8307 - acc: 0.3289 - val_loss: 1.7525 - val_acc: 0.3707\n",
      "Epoch 11/100\n",
      "313/312 [==============================] - 9s 27ms/step - loss: 1.8010 - acc: 0.3445 - val_loss: 1.7536 - val_acc: 0.3739\n",
      "Epoch 12/100\n",
      "313/312 [==============================] - 8s 26ms/step - loss: 1.7825 - acc: 0.3520 - val_loss: 1.7153 - val_acc: 0.3843\n",
      "Epoch 13/100\n",
      "313/312 [==============================] - 8s 26ms/step - loss: 1.7916 - acc: 0.3508 - val_loss: 1.7152 - val_acc: 0.3792\n",
      "Epoch 14/100\n",
      "313/312 [==============================] - 8s 26ms/step - loss: 1.7857 - acc: 0.3516 - val_loss: 1.6928 - val_acc: 0.3920\n",
      "Epoch 15/100\n",
      "313/312 [==============================] - 8s 26ms/step - loss: 1.7680 - acc: 0.3596 - val_loss: 1.6903 - val_acc: 0.3898\n",
      "Epoch 16/100\n",
      "313/312 [==============================] - 8s 26ms/step - loss: 1.7622 - acc: 0.3693 - val_loss: 1.6828 - val_acc: 0.3930\n",
      "Epoch 17/100\n",
      "313/312 [==============================] - 8s 26ms/step - loss: 1.7390 - acc: 0.3693 - val_loss: 1.6748 - val_acc: 0.3958\n",
      "Epoch 18/100\n",
      "313/312 [==============================] - 8s 26ms/step - loss: 1.7649 - acc: 0.3647 - val_loss: 1.7023 - val_acc: 0.3804\n",
      "Epoch 19/100\n",
      "313/312 [==============================] - 8s 27ms/step - loss: 1.7522 - acc: 0.3599 - val_loss: 1.6879 - val_acc: 0.3928\n",
      "Epoch 20/100\n",
      "313/312 [==============================] - 8s 27ms/step - loss: 1.7482 - acc: 0.3641 - val_loss: 1.6724 - val_acc: 0.3997\n",
      "Epoch 21/100\n",
      "313/312 [==============================] - 8s 27ms/step - loss: 1.7394 - acc: 0.3688 - val_loss: 1.6940 - val_acc: 0.3937\n",
      "Epoch 22/100\n",
      "313/312 [==============================] - 8s 27ms/step - loss: 1.7488 - acc: 0.3603 - val_loss: 1.6548 - val_acc: 0.4029\n",
      "Epoch 23/100\n",
      "313/312 [==============================] - 8s 26ms/step - loss: 1.7376 - acc: 0.3694 - val_loss: 1.6595 - val_acc: 0.3999\n",
      "Epoch 24/100\n",
      "313/312 [==============================] - 8s 26ms/step - loss: 1.7329 - acc: 0.3748 - val_loss: 1.6595 - val_acc: 0.4066\n",
      "Epoch 25/100\n",
      "313/312 [==============================] - 8s 26ms/step - loss: 1.7130 - acc: 0.3842 - val_loss: 1.6497 - val_acc: 0.4003\n",
      "Epoch 26/100\n",
      "313/312 [==============================] - 8s 27ms/step - loss: 1.7023 - acc: 0.3849 - val_loss: 1.6460 - val_acc: 0.4083\n",
      "Epoch 27/100\n",
      "313/312 [==============================] - 8s 26ms/step - loss: 1.7251 - acc: 0.3799 - val_loss: 1.6374 - val_acc: 0.4104\n",
      "Epoch 28/100\n",
      "313/312 [==============================] - 8s 27ms/step - loss: 1.7067 - acc: 0.3813 - val_loss: 1.6586 - val_acc: 0.4055\n",
      "Epoch 29/100\n",
      "313/312 [==============================] - 8s 26ms/step - loss: 1.7193 - acc: 0.3722 - val_loss: 1.6569 - val_acc: 0.3998\n",
      "Epoch 30/100\n",
      "313/312 [==============================] - 8s 26ms/step - loss: 1.7262 - acc: 0.3856 - val_loss: 1.6276 - val_acc: 0.4133\n",
      "Epoch 31/100\n",
      "313/312 [==============================] - 8s 26ms/step - loss: 1.6962 - acc: 0.3861 - val_loss: 1.6286 - val_acc: 0.4199\n",
      "Epoch 32/100\n",
      "313/312 [==============================] - 8s 26ms/step - loss: 1.7143 - acc: 0.3871 - val_loss: 1.6251 - val_acc: 0.4128\n",
      "Epoch 33/100\n",
      "313/312 [==============================] - 8s 26ms/step - loss: 1.6932 - acc: 0.3917 - val_loss: 1.6589 - val_acc: 0.4066\n",
      "Epoch 34/100\n",
      "313/312 [==============================] - 8s 25ms/step - loss: 1.7041 - acc: 0.3870 - val_loss: 1.6396 - val_acc: 0.4148\n",
      "Epoch 35/100\n",
      "313/312 [==============================] - 8s 26ms/step - loss: 1.7054 - acc: 0.3875 - val_loss: 1.6547 - val_acc: 0.4043\n",
      "Epoch 36/100\n",
      "313/312 [==============================] - 8s 27ms/step - loss: 1.7080 - acc: 0.3825 - val_loss: 1.6400 - val_acc: 0.4161\n",
      "Epoch 37/100\n",
      "313/312 [==============================] - 9s 27ms/step - loss: 1.7048 - acc: 0.3797 - val_loss: 1.6341 - val_acc: 0.4133\n",
      "Epoch 38/100\n",
      "313/312 [==============================] - 8s 27ms/step - loss: 1.7075 - acc: 0.3846 - val_loss: 1.6389 - val_acc: 0.4101\n",
      "Epoch 39/100\n",
      "313/312 [==============================] - 9s 27ms/step - loss: 1.6945 - acc: 0.3906 - val_loss: 1.6462 - val_acc: 0.4065\n",
      "Epoch 40/100\n",
      "313/312 [==============================] - 8s 27ms/step - loss: 1.6862 - acc: 0.3939 - val_loss: 1.6401 - val_acc: 0.4091\n",
      "Epoch 41/100\n",
      "313/312 [==============================] - 8s 26ms/step - loss: 1.6925 - acc: 0.3939 - val_loss: 1.6139 - val_acc: 0.4246\n",
      "Epoch 42/100\n",
      "313/312 [==============================] - 9s 28ms/step - loss: 1.6871 - acc: 0.3943 - val_loss: 1.6186 - val_acc: 0.4194\n",
      "Epoch 43/100\n",
      "313/312 [==============================] - 9s 29ms/step - loss: 1.6911 - acc: 0.3924 - val_loss: 1.6245 - val_acc: 0.4176\n",
      "Epoch 44/100\n",
      "313/312 [==============================] - 9s 29ms/step - loss: 1.6828 - acc: 0.3941 - val_loss: 1.6152 - val_acc: 0.4223\n",
      "Epoch 45/100\n",
      "313/312 [==============================] - 9s 28ms/step - loss: 1.6900 - acc: 0.3863 - val_loss: 1.6277 - val_acc: 0.4181\n",
      "Epoch 46/100\n",
      "313/312 [==============================] - 9s 29ms/step - loss: 1.6893 - acc: 0.3912 - val_loss: 1.6451 - val_acc: 0.4060\n",
      "Epoch 47/100\n",
      "313/312 [==============================] - 9s 29ms/step - loss: 1.7090 - acc: 0.3871 - val_loss: 1.6156 - val_acc: 0.4240\n",
      "Epoch 48/100\n",
      "313/312 [==============================] - 9s 29ms/step - loss: 1.6872 - acc: 0.3888 - val_loss: 1.6148 - val_acc: 0.4205\n",
      "Epoch 49/100\n",
      "313/312 [==============================] - 9s 30ms/step - loss: 1.6782 - acc: 0.3979 - val_loss: 1.6127 - val_acc: 0.4241\n",
      "Epoch 50/100\n",
      "313/312 [==============================] - 9s 29ms/step - loss: 1.6647 - acc: 0.3987 - val_loss: 1.6188 - val_acc: 0.4188\n",
      "Epoch 51/100\n",
      "313/312 [==============================] - 9s 29ms/step - loss: 1.6708 - acc: 0.4023 - val_loss: 1.6189 - val_acc: 0.4257\n",
      "Epoch 52/100\n",
      "313/312 [==============================] - 9s 29ms/step - loss: 1.6946 - acc: 0.3905 - val_loss: 1.6091 - val_acc: 0.4223\n",
      "Epoch 53/100\n",
      "313/312 [==============================] - 9s 29ms/step - loss: 1.6902 - acc: 0.3887 - val_loss: 1.6032 - val_acc: 0.4240\n",
      "Epoch 54/100\n",
      "313/312 [==============================] - 9s 29ms/step - loss: 1.6837 - acc: 0.3952 - val_loss: 1.6138 - val_acc: 0.4201\n",
      "Epoch 55/100\n",
      "313/312 [==============================] - 9s 29ms/step - loss: 1.6695 - acc: 0.4027 - val_loss: 1.6107 - val_acc: 0.4230\n",
      "Epoch 64/100\n",
      "313/312 [==============================] - 9s 29ms/step - loss: 1.6730 - acc: 0.3967 - val_loss: 1.6271 - val_acc: 0.4103\n",
      "Epoch 65/100\n",
      "313/312 [==============================] - 9s 29ms/step - loss: 1.6661 - acc: 0.4034 - val_loss: 1.6034 - val_acc: 0.4309\n",
      "Epoch 66/100\n",
      "313/312 [==============================] - 9s 29ms/step - loss: 1.6709 - acc: 0.3989 - val_loss: 1.6141 - val_acc: 0.4234\n",
      "Epoch 67/100\n",
      "313/312 [==============================] - 9s 29ms/step - loss: 1.6695 - acc: 0.4048 - val_loss: 1.6053 - val_acc: 0.4245\n",
      "Epoch 68/100\n",
      "313/312 [==============================] - 9s 29ms/step - loss: 1.6610 - acc: 0.4044 - val_loss: 1.6126 - val_acc: 0.4260\n",
      "Epoch 69/100\n",
      "313/312 [==============================] - 9s 29ms/step - loss: 1.6703 - acc: 0.4010 - val_loss: 1.6142 - val_acc: 0.4250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/100\n",
      "313/312 [==============================] - 9s 29ms/step - loss: 1.6825 - acc: 0.3907 - val_loss: 1.6090 - val_acc: 0.4286\n",
      "Epoch 71/100\n",
      "313/312 [==============================] - 9s 28ms/step - loss: 1.6646 - acc: 0.4019 - val_loss: 1.6022 - val_acc: 0.4285\n",
      "Epoch 72/100\n",
      "313/312 [==============================] - 9s 29ms/step - loss: 1.6610 - acc: 0.4012 - val_loss: 1.6536 - val_acc: 0.4167\n",
      "Epoch 73/100\n",
      "313/312 [==============================] - 9s 29ms/step - loss: 1.6705 - acc: 0.3981 - val_loss: 1.6036 - val_acc: 0.4283\n",
      "Epoch 74/100\n",
      "313/312 [==============================] - 9s 29ms/step - loss: 1.6586 - acc: 0.4071 - val_loss: 1.5953 - val_acc: 0.4288\n",
      "Epoch 75/100\n",
      "313/312 [==============================] - 9s 29ms/step - loss: 1.6734 - acc: 0.3974 - val_loss: 1.6106 - val_acc: 0.4235\n",
      "Epoch 76/100\n",
      "313/312 [==============================] - 9s 29ms/step - loss: 1.6738 - acc: 0.3950 - val_loss: 1.6114 - val_acc: 0.4289\n",
      "Epoch 77/100\n",
      "313/312 [==============================] - 9s 29ms/step - loss: 1.6563 - acc: 0.4083 - val_loss: 1.6151 - val_acc: 0.4318\n",
      "Epoch 78/100\n",
      "313/312 [==============================] - 9s 28ms/step - loss: 1.6714 - acc: 0.3978 - val_loss: 1.6009 - val_acc: 0.4270\n",
      "Epoch 79/100\n",
      "313/312 [==============================] - 9s 29ms/step - loss: 1.6640 - acc: 0.4064 - val_loss: 1.6086 - val_acc: 0.4256\n",
      "Epoch 80/100\n",
      "313/312 [==============================] - 9s 29ms/step - loss: 1.6645 - acc: 0.4031 - val_loss: 1.6051 - val_acc: 0.4321\n",
      "Epoch 81/100\n",
      "313/312 [==============================] - 9s 29ms/step - loss: 1.6565 - acc: 0.4084 - val_loss: 1.6020 - val_acc: 0.4271\n",
      "Epoch 82/100\n",
      "313/312 [==============================] - 9s 29ms/step - loss: 1.6684 - acc: 0.4032 - val_loss: 1.6141 - val_acc: 0.4226\n",
      "Epoch 83/100\n",
      "313/312 [==============================] - 9s 29ms/step - loss: 1.6682 - acc: 0.4008 - val_loss: 1.6125 - val_acc: 0.4273\n",
      "Epoch 84/100\n",
      "313/312 [==============================] - 9s 29ms/step - loss: 1.6711 - acc: 0.4000 - val_loss: 1.6213 - val_acc: 0.4223\n",
      "Epoch 85/100\n",
      "313/312 [==============================] - 9s 28ms/step - loss: 1.6553 - acc: 0.4096 - val_loss: 1.5983 - val_acc: 0.4291\n",
      "Epoch 86/100\n",
      "313/312 [==============================] - 9s 28ms/step - loss: 1.6687 - acc: 0.4019 - val_loss: 1.6043 - val_acc: 0.4297\n",
      "Epoch 87/100\n",
      "313/312 [==============================] - 9s 28ms/step - loss: 1.6557 - acc: 0.4101 - val_loss: 1.6082 - val_acc: 0.4262\n",
      "Epoch 88/100\n",
      "313/312 [==============================] - 9s 28ms/step - loss: 1.6596 - acc: 0.4033 - val_loss: 1.5933 - val_acc: 0.4306\n",
      "Epoch 89/100\n",
      "313/312 [==============================] - 9s 29ms/step - loss: 1.6517 - acc: 0.4085 - val_loss: 1.6216 - val_acc: 0.4338\n",
      "Epoch 90/100\n",
      "313/312 [==============================] - 8s 26ms/step - loss: 1.6767 - acc: 0.4021 - val_loss: 1.6036 - val_acc: 0.4303\n",
      "Epoch 91/100\n",
      "313/312 [==============================] - 9s 28ms/step - loss: 1.6493 - acc: 0.4148 - val_loss: 1.6242 - val_acc: 0.4185\n",
      "Epoch 92/100\n",
      "313/312 [==============================] - 9s 29ms/step - loss: 1.6533 - acc: 0.4103 - val_loss: 1.6193 - val_acc: 0.4253\n",
      "Epoch 93/100\n",
      "313/312 [==============================] - 9s 29ms/step - loss: 1.6560 - acc: 0.4051 - val_loss: 1.6024 - val_acc: 0.4286\n",
      "Epoch 94/100\n",
      "313/312 [==============================] - 9s 29ms/step - loss: 1.6696 - acc: 0.4086 - val_loss: 1.5947 - val_acc: 0.4345\n",
      "Epoch 95/100\n",
      "313/312 [==============================] - 9s 29ms/step - loss: 1.6684 - acc: 0.4013 - val_loss: 1.6030 - val_acc: 0.4252\n",
      "Epoch 96/100\n",
      "313/312 [==============================] - 9s 28ms/step - loss: 1.6760 - acc: 0.3943 - val_loss: 1.6072 - val_acc: 0.4258\n",
      "Epoch 97/100\n",
      "313/312 [==============================] - 9s 28ms/step - loss: 1.6527 - acc: 0.4055 - val_loss: 1.6272 - val_acc: 0.4185\n",
      "Epoch 98/100\n",
      "313/312 [==============================] - 9s 28ms/step - loss: 1.6621 - acc: 0.3995 - val_loss: 1.6183 - val_acc: 0.4303\n",
      "Epoch 99/100\n",
      "313/312 [==============================] - 9s 29ms/step - loss: 1.6603 - acc: 0.4078 - val_loss: 1.6122 - val_acc: 0.4323\n",
      "Epoch 100/100\n",
      "313/312 [==============================] - 9s 29ms/step - loss: 1.6629 - acc: 0.4092 - val_loss: 1.6034 - val_acc: 0.4319\n",
      "10000/10000 [==============================] - 1s 81us/step\n",
      "Test loss: 1.6033517513275146\n",
      "Test accuracy: 0.4319\n"
     ]
    }
   ],
   "source": [
    " model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                     batch_size=batch_size),\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(x_test, y_test),workers=4,steps_per_epoch=len(x_test)/32)\n",
    "\n",
    "\n",
    "# Scores for model\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
